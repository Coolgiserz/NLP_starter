# 自监督学习

自监督学习是什么？跟监督学习、无监督学习、半监督学习、弱监督学习的关系是什么？预训练和自监督学习的关系是？

自监督学习是为了解决什么问题？

目前自监督学习方法可以分为哪些流派？各自的优势在哪里？

自监督学习能够做些什么？

还可以从哪些思路进行自监督学习？

自监督学习有无什么内在的缺陷/瓶颈？

研究者/业界对于自监督学习的观点是？

## 概念/引言

自监督学习提出的目的在于：希望从大量的无标注数据中学习到有用的表示。针对图数据来说，无标注数据的单元可以图本身或者图中的节点、边等。针对图像来说，无标注数据的单元可以是图像或图像中的目标、像元。

自监督学习提出的背景在于：深度学习大量依赖于有标签的数据，而现实情况下并没有那么多带标签数据（标注成本高、耗时），即便是ImageNet这么大的人工标注数据集，相比于现实世界的数据规模而言，也是微不足道的。所以研究通过无监督学习的方式学习数据表示是有重要意义的。

##### 自监督学习与无监督学习、半监督学习、弱监督学习的关系是？

### 自监督信息

自监督学习希望学到数据中的哪些信息？

#### 图像的自监督学习

#### 文本的自监督学习

#### 图上的自监督学习

学习节点嵌入，同时捕获到节点特征和图结构信息。

## 方法

### 自监督学习的方法流派

- 基于上下文信息的自监督（生成式、预测式）

  取决于如何定义上下文。自然语言中字词与字词之间的位置关系是一种上下文；视频数据中帧与帧之间的时序信息也是一种上下文。

- 基于对比学习的自监督

  ……

### 面向自然语言处理的自监督学习

主要是基于上下文的自监督学习方法。

### 面向图像数据的自监督学习

对比学习。

### 面向图数据的自监督学习

对比学习、预测式。

## 应用

## 新方向

自监督学习的挑战在？

- 自监督信息与具体任务的领域信息结合

  不追求从一套或几套超大规模数据集中提取一套“通用”的特征以辅助下游任务。而是直接将自监督任务（从无标注数据中提取特征）与具体领域任务（从带标注数据中学习知识）结合处理任务。

  这样虽然不似ImageNet预训练模型或文本领域的BERT模型那般提供一个预先训练好的通用特征，但对于具体任务来进行训练也未尝不可。

  SelfTask

- 语义信息

- ……

## 对于一些观点的认识/反驳

##### “目前图上的自监督学习不做到时序上就是没有意义的工作”

目前关于图上的自监督学习大多针对静态图，有人提出“目前图上的自监督学习不做到时序上就是没有意义的工作”。按照这个逻辑，可以说再做图上的自监督学习是没有意义的，因为已经有很多人做了。

但是，什么是“没有意义”、什么叫“很多人在做”都是很模糊的说法。如果不具体细化分析，那这个观点本身是没有意义的，即伪命题。

##### ImageNet预训练模型有什么问题吗？

##### 存在一种通用且可迁移的特征吗？

##### 为什么可以通过无监督的方式学习？基于什么假设？

数据本身就蕴含了足够丰富的信息。

##### 为什么对节点子图进行采样来作为数据增强手段？

n-hop子图中，几跳子图采样最为合适？

##### 为什么需要领域信息？

本人倾向于认为不存在一个通用的模型适用于所有领域。

## 参考资料

### 论文

- Self-supervised Learning on Graphs：Deep Insights and New Directions
- ……

### 教材

### 博客

- Self-supervised Learning 再次入门：https://zhuanlan.zhihu.com/p/108906502
- 自监督学习(Self-supervised Learning)是何方神圣？：https://zhuanlan.zhihu.com/p/125721565
- 图上的自监督学习——对比学习论文解读：https://llijiajun.github.io/github-io/2020-08-14/Article-02
- ……

### 实验室

